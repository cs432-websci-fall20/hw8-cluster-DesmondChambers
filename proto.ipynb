{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse feed http://www.blogmaverick.com/rss.xml\n",
      "\n",
      "Failed to parse feed http://rss.cnn.com/rss/disruptors\n",
      "\n",
      "Failed to parse feed feed://www.contentinople.com/rss_simple.asp\n",
      "\n",
      "Failed to parse feed http://feeds.feedburner.com/crunchnotes\n",
      "\n",
      "Failed to parse feed http://www.davideckoff.com/atom.xml\n",
      "\n",
      "Failed to parse feed http://www.dmwmedia.com/taxonomy/term/617/all/feed\n",
      "\n",
      "Beet.TV\n",
      "Bits\n",
      "CinemaTech\n",
      "Data Center Knowledge\n",
      "Digital Knowledge\n",
      "Digital Vista\n",
      "eMarketer Articles and Newsroom Posts\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "import feedparser\n",
    "import re\n",
    "\n",
    "def getwordcounts(url):\n",
    "    '''\n",
    "    Returns title and dictionary of word counts for an RSS feed\n",
    "    '''\n",
    "    # Parse the feed\n",
    "    d = feedparser.parse(url)\n",
    "    wc = {}\n",
    "\n",
    "    # Loop over all the entries\n",
    "    for e in d.entries:\n",
    "        if 'summary' in e:\n",
    "            summary = e.summary\n",
    "\n",
    "        else:\n",
    "            summary = e.description\n",
    "\n",
    "        # Extract a list of words\n",
    "        words = getwords(e.title + ' ' + summary)\n",
    "        for word in words:\n",
    "            wc.setdefault(word, 0)\n",
    "            wc[word] += 1\n",
    "\n",
    "    return (d.feed.title, wc)\n",
    "\n",
    "\n",
    "def getwords(html):\n",
    "    # Remove all the HTML tags\n",
    "    txt = re.compile(r'<[^>]+>').sub('', html)\n",
    "\n",
    "    # Split words by all non-alpha characters\n",
    "    words = re.compile(r'[^A-Z^a-z]+').split(txt)\n",
    "    #print(words)\n",
    "    # Convert to lowercase\n",
    "    return [word.lower() for word in words if word != '']\n",
    "\n",
    "\n",
    "apcount = {}\n",
    "wordcounts = {}\n",
    "file1 = open('feedlist.txt', 'r') \n",
    "feedlist = file1.readlines() \n",
    "  \n",
    "count = 0\n",
    "# Strips the newline character \n",
    "#for line in Lines: \n",
    "for feedurl in feedlist:\n",
    "    try:\n",
    "        (title, wc) = getwordcounts(feedurl)\n",
    "        wordcounts[title] = wc\n",
    "        for (word, count) in wc.items():\n",
    "            apcount.setdefault(word, 0)\n",
    "            if count > 1:\n",
    "                apcount[word] += 1\n",
    "    except:\n",
    "        print ('Failed to parse feed %s' % feedurl)\n",
    "\n",
    "wordlist = []\n",
    "for (w, bc) in apcount.items():\n",
    "    frac = float(bc) / len(feedlist)\n",
    "    if frac > 0.1 and frac < 0.5:\n",
    "        wordlist.append(w)\n",
    "\n",
    "#file1 = open(\"MyFile.txt\", \"w\") \n",
    "out = open(\"blogdata1.txt\", \"w\") \n",
    "out.write('Blog')\n",
    "for word in wordlist:\n",
    "    out.write('\\t%s' % word)\n",
    "out.write('\\n')\n",
    "for (blog, wc) in wordcounts.items():\n",
    "    print (blog)\n",
    "    out.write(blog)\n",
    "    for word in wordlist:\n",
    "        if word in wc:\n",
    "            out.write('\\t%d' % wc[word])\n",
    "        else:\n",
    "            out.write('\\t0')\n",
    "    out.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse feed http://www.blogmaverick.com/rss.xml\n",
      "\n",
      "Failed to parse feed http://rss.cnn.com/rss/disruptors\n",
      "\n",
      "Failed to parse feed feed://www.contentinople.com/rss_simple.asp\n",
      "\n",
      "Failed to parse feed http://feeds.feedburner.com/crunchnotes\n",
      "\n",
      "Failed to parse feed http://www.davideckoff.com/atom.xml\n",
      "\n",
      "Failed to parse feed http://www.dmwmedia.com/taxonomy/term/617/all/feed\n",
      "\n",
      "Beet.TV\n",
      "Bits\n",
      "CinemaTech\n",
      "Data Center Knowledge\n",
      "Digital Knowledge\n",
      "Digital Vista\n",
      "eMarketer Articles and Newsroom Posts\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "import feedparser\n",
    "import re\n",
    "\n",
    "def getwordcounts(url):\n",
    "    '''\n",
    "    Returns title and dictionary of word counts for an RSS feed\n",
    "    '''\n",
    "    # Parse the feed\n",
    "    d = feedparser.parse(url)\n",
    "    wc = {}\n",
    "\n",
    "    # Loop over all the entries\n",
    "    for e in d.entries:\n",
    "        if 'summary' in e:\n",
    "            summary = e.summary\n",
    "\n",
    "        else:\n",
    "            summary = e.description\n",
    "\n",
    "        # Extract a list of words\n",
    "        words = getwords(e.title + ' ' + summary)\n",
    "        for word in words:\n",
    "            wc.setdefault(word, 0)\n",
    "            wc[word] += 1\n",
    "\n",
    "    return (d.feed.title, wc)\n",
    "\n",
    "\n",
    "def getwords(html):\n",
    "    # Remove all the HTML tags\n",
    "    txt = re.compile(r'<[^>]+>').sub('', html)\n",
    "\n",
    "    # Split words by all non-alpha characters\n",
    "    words = re.compile(r'[^A-Z^a-z]+').split(txt)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    return [word.lower() for word in words if word != '']\n",
    "\n",
    "\n",
    "apcount = {}\n",
    "wordcounts = {}\n",
    "file1 = open('feedlist.txt', 'r') \n",
    "feedlist = file1.readlines() \n",
    "  \n",
    "for feedurl in feedlist:\n",
    "    try:\n",
    "        (title, wc) = getwordcounts(feedurl)\n",
    "        wordcounts[title] = wc\n",
    "        for (word, count) in wc.items():\n",
    "            apcount.setdefault(word, 0)\n",
    "            if count > 1:\n",
    "                apcount[word] += 1\n",
    "    except:\n",
    "        print ('Failed to parse feed %s' % feedurl)\n",
    "\n",
    "wordlist = []\n",
    "for (w, bc) in apcount.items():\n",
    "    frac = float(bc) / len(feedlist)\n",
    "    if frac > 0.1 and frac < 0.5:\n",
    "        wordlist.append(w)\n",
    "\n",
    "out = open(\"blogdata1.txt\", \"w\") \n",
    "out.write('Blog')\n",
    "for word in wordlist:\n",
    "    out.write('\\t%s' % word)\n",
    "out.write('\\n')\n",
    "for (blog, wc) in wordcounts.items():\n",
    "    print (blog)\n",
    "    out.write(blog)\n",
    "    for word in wordlist:\n",
    "        if word in wc:\n",
    "            out.write('\\t%d' % wc[word])\n",
    "        else:\n",
    "            out.write('\\t0')\n",
    "    out.write('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
